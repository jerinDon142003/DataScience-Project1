# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AMNeykS2bJbLmY66ysNOZZKQ3pBeb3Xc
"""

!pip install yfinance

!pip install pandas

import yfinance as yf
import pandas as pd

apple= yf.Ticker("AAPL")

!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/data/apple.json

import json
with open('apple.json') as json_file:
  apple_info= json.load(json_file)
apple_info

apple_share_price_data= apple.history(period="max")
apple_share_price_data

apple_share_price_data.head()

apple_share_price_data.reset_index(inplace=True)

!pip install matplotlib

apple_share_price_data.head()

import matplotlib as plot

apple_share_price_data.plot(x="Date", y= "Open")

!pip install pandas

!pip install requests
!pip install bs4
!pip install html5lib
!pip install lxml
!pip install plotly

import pandas as pd
import requests
from bs4 import BeautifulSoup

import warnings
warnings.filterwarnings("ignore", category= FutureWarning)

#Step 1: Send an HTTP request to the web page

url= "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/netflix_data_webpage.html"

data= requests.get(url).text
print(data)

#Step 2: Parse the HTML content

soup= BeautifulSoup(data, "html.parser")

print(soup)

#step 3: IDentify the HTML Tags
netflix_data= pd.DataFrame(columns= ["Date", "Open", "High", "Low", "Close", "Volume"])

print(netflix_data)

# Step 4: Use a BeautifulSoup method for extracting data

for row in soup.find("tbody").find_all("tr"):
  col= row.find_all("td")
  date= col[0].text
  Open= col[1].text
  high= col[2].text
  low= col[3].text
  close= col[4].text
  adj_close= col[5].text
  volume= col[6].text
  netflix_data= pd.concat([netflix_data, pd.DataFrame({"Date":[date], "Open":[Open], "High":[high], "Low":[low], "Close":[close], "Adj Close":[adj_close], "Volume":[volume]})], ignore_index=True)

print(netflix_data.head())

#Extracting data using Pandas library

read_html_pandas_data= pd.read_html(url)

netflix_dataframe= read_html_pandas_data[0]
netflix_dataframe.head()

#Exercise: Use Webscraping to extract stock data

url1= "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/amazon_data_webpage.html"

html_data= requests.get(url1).text

data1= BeautifulSoup(html_data, "html.parser")

print(pd.read_html(str(data1)))

amazon_data = pd.DataFrame(columns=["Date", "Open", "High", "Low", "Close", "Volume"])

for row in soup.find("tbody").find_all("tr"):
    col = row.find_all("td")
    date = col[0].text
    Open = col[1].text
    high = col[2].text
    low = col[3].text
    close = col[4].text
    adj_close = col[5].text
    volume = col[6].text

    amazon_data = pd.concat([amazon_data, pd.DataFrame({"Date":[date], "Open":[Open], "High":[high], "Low":[low], "Close":[close], "Adj Close":[adj_close], "Volume":[volume]})], ignore_index=True)

print(amazon_data.head())

# prompt: what are teh names of the columns in the data frame?

netflix_data.columns

print(netflix_data.tail())

# prompt: what is the open of the last row of the amazon_data data frame?

amazon_data.iloc[-1]['Open']

